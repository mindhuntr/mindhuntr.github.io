+++
date = '2025-06-26T09:48:15+05:30'
title = 'The AI Hype'
description = 'Is AI truly revolutionary?'
tags = ['unix', 'ai']
+++

In a previous blog of mine on Linux, I talk about how the commonplace ignorance towards technology is becoming more detrimental with each day. This is an idea that one of my favourite writers Niel Stepehnson introduced in his essay "[In the Beginning was the Command Line](https://web.stanford.edu/class/cs81n/command.txt)". To provide a brief summary, the essay outlines the development of major operating systems and reflects on how since the inception of the "GUI", end users have come to increasingly relinquish the control they have over computers. Ease of use always entails a certain amount of ignorance and sometimes it is warranted. But when this interface, which is supposed to facilitate unmitigated communication, falsifies or subtly leads you towards performing a specific task, it becomes something else entirely. 

I have found this frame of reference extremely useful in discerning between good and bad software. If a particular program strives to be transparent and fulfills its task as effectively as possible, I usually consider it well written. Recently I have been exposed to a fair bit of discourse surrounding AI which prompted me to evaluate it along these lines. While some regard the technology to be revolutionary, others dismiss it altogether on the basis of describing AI to be nothing more than a glorified auto complete. 

I personally err towards the latter side of the debate for both personal and general reasons. In my experience using AI, properly called LLM, I have found it useful in certain respects. It can rearrange text quite efficiently and might even be useful for looking up syntax or documentation for commands. But when you engage the LLM with more sophisticated tasks, even if it is strictly confined to programming, it is needless to say that it fails rather miserably. This limitation of LLMs and its inability to generalize in any meaningful sense arises because LLMs do not understand. They simply predict the next word in a given prompt, creating a feeble illusion of intelligence that crumbles almost instantly with scrutiny. 

I find this predictive nature of LLMs problematic for many reasons but mostly because of how it deceives someone of what it actually offers. As you enter a prompt in ChatGPT or Gemini, what you get in response gives you all the impression of some rudimentary intelligence at work but the truth couldn't be farther from it. However there's an even more alarming concern. With the rise of "Vibe Coding" and the general practice of using LLMs to sidestep any serious writing, especially in Academia, this technology also appears to be a fuelling a culture of mediocrity. 

Under the pretense of letting AI do all the hard work, its users become increasingly detached from a particular task, settling either for sloppy code that just works or content that barely passes off as human. In the context of our interface analogy, its not just that AI throws a veil on the machine you use but rather on life itself as it removes you from fully engaging in pursuits that are of inherent value. Both in education and perhaps even in the world at large, AI is assuming the role of an interface for living in a culture that cares more about appearance and quantity than anything else.  

A good tool is always marked by an ability to bring you closer to the work at hand. It doesn't just make things easier but also provides a conduit through which you can understand and derive lasting value from whatever you are doing. In our pursuit of seeking expedience, I believe we have reached a point where mindless work is being praised as technological breakthrough. And if it is anything that LLMs presage, it is our credulity to unthinkingly accept any novel innovation in the name of progress. 
